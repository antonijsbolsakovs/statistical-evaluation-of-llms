# Statistical Evaluation of LLMs

This is a group project from DTU (Course 02445: Statistical Evaluation for Artificial Intelligence and Data).

## 📌 Project Overview
We evaluated **language interference** in Large Language Models (Gemini 1.5 vs 2.0).  
The focus was on how prompt structure influences responses in bilingual contexts (Danish-English).  

Statistical methods included:
- ANOVA
- Regression analysis
- Correlation analysis

## 🛠️ Stack
- Python (Pandas, Scikit-learn, Matplotlib)
- R (for additional statistical testing)
- CSV datasets & statistical plots

## 🔑 Results
- Clear evidence of differences between Gemini 1.5 and 2.0 in handling bilingual prompts.
- Quantitative evaluation using reproducible scripts and statistical tests.

## 👥 Teamwork
This was a **group project** with 4 contributors.  
I was responsible for:
- Implementing Python scripts for data cleaning and analysis
- Running ANOVA and correlation analysis
- Contributing to the final report and presentation
